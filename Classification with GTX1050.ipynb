{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAIDsK4nKOXc",
    "tags": []
   },
   "source": [
    "# **Improving Brain Tumor Classification through MRI Images**\n",
    "\n",
    "Given the limited access to the Tesla T4 GPU on Google Colab’s free plan, I aim to leverage my GTX 1050 Ti for training and explore its effectiveness. Specifically, I intend to compare training speeds between Colab's CPU and my GTX 1050 Ti, assessing their impact on training time and overall model efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3svYHisKuV-"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "The previous models, including MLP, AlexNet, and Inception-v3, demonstrated low macro accuracy and recall (approximately 0.2), with Cohen's Kappa effectively at 0 thus indicating that the models’ predictions are almost entirely random and lack agreement with the ground truth. To improve performance metrics such as accuracy, recall, F1 score, and Cohen’s Kappa, I plan to train an EfficientNet B0 model on a GTX 1050 Ti, implementing the following modifications:\n",
    "\n",
    "- Evaluating the impact of no augmentation and various augmentation strategies (using weighted metrics).\n",
    "- Training on individual anatomical planes (axial, sagittal, and coronal) separately.\n",
    "- Utilizing different datasets for comparative analysis.\n",
    "\n",
    "Following this, additional models, such as VGG16 and Inception-v3, will be tested with these modifications to assess their effects on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UEasYfgLmQG"
   },
   "source": [
    "# **2 Checking OS Version and GPU Details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwbBSIuAwSJK",
    "outputId": "040f4464-211c-454f-9db8-e39c72ee9762"
   },
   "outputs": [],
   "source": [
    "print(\"OS Version & Details: \")\n",
    "!systeminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "\n",
    "print(\"NVIDIA GPU Information:\")\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU ID: {gpu.id}\")\n",
    "    print(f\"Name: {gpu.name}\")\n",
    "    print(f\"Driver Version: {gpu.driver}\")\n",
    "    print(f\"Total Memory: {gpu.memoryTotal} MB\")\n",
    "    print(f\"Free Memory: {gpu.memoryFree} MB\")\n",
    "    print(f\"Used Memory: {gpu.memoryUsed} MB\")\n",
    "    print(f\"Temperature: {gpu.temperature} °C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6yl8ItXKyfv"
   },
   "source": [
    "# **3. Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsC7DKICTTO3",
    "outputId": "fa92a56c-3701-4dc9-d740-2469ed0acd52"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.dpi'] = 300\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "\n",
    "print(f'Tensorflow Version: {tf.__version__}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pefZGakCLvRd"
   },
   "source": [
    "# **4. Setting Up the Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_i1l94vmxDP0",
    "outputId": "5346ee93-50c8-4fa9-c77e-25d3e37d2980"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Available GPUs: {gpus}\")\n",
    "else:\n",
    "    print(\"No GPUs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q3DOx3gL-0M"
   },
   "source": [
    "## **4.1 Installation of `tree` Utility Using `Bash`.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hgj7gTPggUru",
    "outputId": "55f38fbe-579d-41ac-995c-7007aa517c57"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "RED_COLOR='\\033[0;31m'\n",
    "NO_COLOR='\\033[0m'\n",
    "pkg_name=tree\n",
    "dpkg -s $pkg_name &> /dev/null\n",
    "if [ \"$?\" -ne \"0\" ]\n",
    "    then\n",
    "        echo \"Installing tree utility...\"\n",
    "        apt-get autoclean\n",
    "        apt-get autoremove\n",
    "        apt-get install $pkg_name\n",
    "        if [ \"$?\" -eq \"0\" ]\n",
    "            then\n",
    "                echo -e ${RED_COLOR}\"tree utility installed sucessfully.\\n\"${NO_COLOR}\n",
    "        fi\n",
    "    else\n",
    "        echo \"tree utility is already installed.\"\n",
    "fi\n",
    "tree --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rSn4v8bMJEK"
   },
   "source": [
    "## **4.2 Display of File Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNz7YWv3fx3C",
    "outputId": "a5359003-ab1c-42b0-d7ee-cf109ff24047"
   },
   "outputs": [],
   "source": [
    "!tree -d \"/content/gdrive/MyDrive/Colab Notebooks/BrainTumorDataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ta1TX_tMUQl"
   },
   "source": [
    "## **4.3 Setting Up Paths to Root and Data Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkxWgEs-CXgi"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = r\"/content/gdrive/MyDrive/Colab Notebooks/BrainTumorDataset\"\n",
    "DATA_ROOT_DIR = os.path.join(ROOT_DIR, \"Brain-Tumor-Dataset\")\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT_DIR, 'Training')\n",
    "MASK_DIR = os.path.join(DATA_ROOT_DIR, 'Tumor-Mask')\n",
    "assert os.path.isdir(ROOT_DIR) and os.path.isdir(DATA_ROOT_DIR) and os.path.isdir(TRAIN_DIR) and os.path.isdir(MASK_DIR)\n",
    "TUMOR_CLASS = ['meningioma', 'glioma', 'pituitary_tumor', 'no_tumor']\n",
    "IMAGE_DATA_PATHS = [os.path.join(TRAIN_DIR, tumor_class) for tumor_class in TUMOR_CLASS]\n",
    "MASK_DATA_PATHS = [os.path.join(MASK_DIR, tumor_name) for tumor_name in TUMOR_CLASS[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "389an7U5Mf41"
   },
   "source": [
    "# **5. Data Preprocessing and Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "mWyoNwqsMfAB",
    "outputId": "f3e3520d-400e-49b8-f99a-0b119dc43abf"
   },
   "outputs": [],
   "source": [
    "data_distribution_count = pd.Series([len(os.listdir(path)) for path in IMAGE_DATA_PATHS if os.path.exists(path) and os.path.isdir(path)],\n",
    "                                    index = TUMOR_CLASS)\n",
    "data_distribution_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX_KSI0NMsaS"
   },
   "source": [
    "## **5.1 Data Distribution Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "CtEyuefeHADS",
    "outputId": "3ebfa44d-0d2d-4236-afa8-9a49a72f00bd"
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize = (13, 5))\n",
    "axis.grid(True, alpha = 0.1)\n",
    "axis.set_title(\"Data Distribution Percentage (%)\", fontsize = 14)\n",
    "sns.barplot(x = ['\\n'.join(curr_index.strip().split('_')).title() for curr_index in data_distribution_count.index],\n",
    "            y = 100 * (data_distribution_count / data_distribution_count.sum()),\n",
    "            ax = axis,\n",
    "            palette=\"Set1\",\n",
    "            hue=['\\n'.join(curr_index.strip().split('_')).title() for curr_index in data_distribution_count.index])\n",
    "axis.set_xlabel(\"Tumor Class\", fontsize = 12)\n",
    "axis.set_ylabel(\"% Total Observations\", fontsize = 12)\n",
    "axis.tick_params(which = 'major', labelsize = 12)\n",
    "axis.text(2.5, 37, f'Total Observations: {data_distribution_count.sum()}', fontdict = dict(size = 12))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD9dFbSQNDd4"
   },
   "source": [
    "## **5.2 Visualisation of Brain MRI Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aref3Kt5Q-9V"
   },
   "source": [
    "**Dataset Source: https://figshare.com/articles/dataset/brain_tumor_dataset/1512427**  \n",
    "\n",
    "**Source Code for Conversion of `.mat` file to `.jpg`: [Google Colab Notebook Link](https://colab.research.google.com/drive/1aucu3Ipj1eS0y1YEzKq76Z38TaetHSc3?usp=sharing)**  \n",
    "\n",
    "**Final Dataset Link: https://drive.google.com/drive/folders/11QIC82FBdAyq0PUwLVNd22i-oq6lcat1?usp=sharing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "PIoMFGLbDnDC",
    "outputId": "d2ec2780-65ea-4564-e1fe-d3678fd1a0f2"
   },
   "outputs": [],
   "source": [
    "BRIGHTNESS_FACTOR = 1.7\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 3, figsize = (18, 9))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle(\"Brain Tumor MRI Images (T2w)\", fontsize = 16, fontdict = dict(weight = 'bold'), y = 1.04)\n",
    "for curr_title, filename, curr_axis in zip(TUMOR_CLASS[:-1], IMAGE_DATA_PATHS[:-1], axes[:3]):\n",
    "    curr_image = Image.open(os.path.join(filename, os.listdir(filename)[2]))\n",
    "    img_enhancer = ImageEnhance.Brightness(curr_image)\n",
    "    curr_axis.imshow(img_enhancer.enhance(BRIGHTNESS_FACTOR))\n",
    "    curr_axis.set_title(\" \".join(curr_title.split('_')).title(), fontsize = 14)\n",
    "\n",
    "for filename, curr_axis in zip(MASK_DATA_PATHS, axes[3:]):\n",
    "    curr_image = Image.open(os.path.join(filename, os.listdir(filename)[2]))\n",
    "    mask_enhancer = ImageEnhance.Brightness(curr_image)\n",
    "    curr_axis.imshow(mask_enhancer.enhance(BRIGHTNESS_FACTOR))\n",
    "fig.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVJ0cTJ7bHE3"
   },
   "source": [
    "## **6. Development of Training, Validation & Testing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJPk6GkYlpCI"
   },
   "outputs": [],
   "source": [
    "image_data_paths = []\n",
    "for curr_path, tumor_name in zip(IMAGE_DATA_PATHS, TUMOR_CLASS):\n",
    "    if os.path.exists(curr_path) and os.path.isdir(curr_path):\n",
    "        image_data_paths.extend(map(lambda filename: (os.path.join(curr_path, filename), tumor_name), os.listdir(curr_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y3LW1gM_gK20",
    "outputId": "54ebc3e7-7c1a-4de7-b534-1c36bb262bfd"
   },
   "outputs": [],
   "source": [
    "image_data_paths_df = pd.DataFrame(image_data_paths, columns = ['image_filepaths', 'tumor_class']).sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "image_data_paths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPrZmgU2t6bH",
    "outputId": "40635160-2e0b-475c-f3aa-5e10385185cc"
   },
   "outputs": [],
   "source": [
    "image_data_paths_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0NgLV0LvBsf"
   },
   "outputs": [],
   "source": [
    "intermediate_train_data, test_data = train_test_split(image_data_paths_df,\n",
    "                                                      train_size = 0.70,\n",
    "                                                      random_state = 42,\n",
    "                                                      stratify = image_data_paths_df.tumor_class)\n",
    "\n",
    "train_data, validation_data = train_test_split(intermediate_train_data,\n",
    "                                               train_size = 0.80,\n",
    "                                               random_state = 42,\n",
    "                                               stratify = intermediate_train_data.tumor_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJgD4V3GNZjW"
   },
   "source": [
    "## **6.1 Training, Validation and Testing Dataset Data Distribution Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "ayIe4k7FwDpo",
    "outputId": "b3f60c3c-d677-4c73-d5dc-51f78b52993b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols = 3, figsize = (20, 5))\n",
    "fig.suptitle(\"Distribution of Training/Validation/Testing Data\", fontsize = 16, fontdict = dict(weight = 'bold'), y = 1.05)\n",
    "sns.countplot(x = train_data.tumor_class, order = TUMOR_CLASS, ax = axes[0], palette = \"Set1\", hue = train_data.tumor_class)\n",
    "sns.countplot(x = validation_data.tumor_class, order = TUMOR_CLASS, ax = axes[1], palette = \"Set1\", hue = validation_data.tumor_class)\n",
    "sns.countplot(x = test_data.tumor_class, order = TUMOR_CLASS, ax = axes[2], palette = \"Set1\", hue = test_data.tumor_class)\n",
    "for curr_axis, curr_title in zip(axes, ['Train Data', 'Validation Data', 'Test Data']):\n",
    "    curr_axis.grid(alpha = 0.1)\n",
    "    curr_axis.set_title(curr_title, fontsize = 12)\n",
    "    curr_axis.set_xlabel(\"Tumor Classes\", fontsize = 12)\n",
    "    curr_axis.set_ylabel(\"Total Observations\", fontsize = 12)\n",
    "    curr_axis.tick_params(which = 'major', labelsize = 12)\n",
    "    curr_axis.set_xticks(range(len(TUMOR_CLASS)), TUMOR_CLASS, fontsize = 12)\n",
    "    curr_axis.set_xticklabels([\"\\n\".join(xtick.split(\"_\")).title() for xtick in TUMOR_CLASS])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43nahGE8yjJ-"
   },
   "source": [
    "# **7. Data/Image Augmentation**\n",
    "* Image augmentation is usually used to increase the image dataset and also to make the network more robust against translation invariance. Image augmentation is defined as creating duplicates of the original image datasets by flipping, rotating, zooming, and adjusting brightness.\n",
    "\n",
    "* We will use data/image augmentation using `ImageDataGenerator` class to train the model on different types of combinations formed by rotation, flipping, changing the brightness etc of an image so as to increase our model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w5KDl17UX49"
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "image_datagen_kwargs = dict(rescale = 1 / 255,\n",
    "                            rotation_range = 15,\n",
    "                            width_shift_range = 0.1,\n",
    "                            zoom_range = 0.01,\n",
    "                            shear_range = 0.01,\n",
    "                            brightness_range = [0.3, 1.5],\n",
    "                            horizontal_flip = True,\n",
    "                            vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwsd1D3DwgKx"
   },
   "outputs": [],
   "source": [
    "train_image_datagen = ImageDataGenerator(**image_datagen_kwargs)\n",
    "validation_image_datagen = ImageDataGenerator(**image_datagen_kwargs)\n",
    "test_image_datagen = ImageDataGenerator(**image_datagen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pN5rSeDXw89O",
    "outputId": "4d9fd235-c731-4235-f3af-2ea4ba4555e6"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_image_datagen.flow_from_dataframe(train_data,\n",
    "                                                        x_col = 'image_filepaths',\n",
    "                                                        y_col = 'tumor_class',\n",
    "                                                        seed = 42,\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        target_size = (image_size, image_size),\n",
    "                                                        color_mode = 'rgb')\n",
    "validation_dataset = validation_image_datagen.flow_from_dataframe(validation_data,\n",
    "                                                                  x_col = 'image_filepaths',\n",
    "                                                                  y_col = 'tumor_class',\n",
    "                                                                  seed = 42,\n",
    "                                                                  batch_size = batch_size,\n",
    "                                                                  target_size = (image_size, image_size),\n",
    "                                                                  color_mode = 'rgb')\n",
    "test_dataset = test_image_datagen.flow_from_dataframe(test_data,\n",
    "                                                      x_col = 'image_filepaths',\n",
    "                                                      y_col = 'tumor_class',\n",
    "                                                      seed = 42,\n",
    "                                                      batch_size = batch_size,\n",
    "                                                      target_size = (image_size, image_size),\n",
    "                                                      color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIDhu-NQ5myG",
    "outputId": "e57bd269-cfd6-46b8-926d-a48355594b34"
   },
   "outputs": [],
   "source": [
    "print(\"Information about Training Dataset:\")\n",
    "print(train_dataset.class_indices)\n",
    "print(train_dataset.image_shape, end = '\\n\\n')\n",
    "\n",
    "print(\"Information about Validation Dataset:\")\n",
    "print(validation_dataset.class_indices)\n",
    "print(validation_dataset.image_shape, end = '\\n\\n')\n",
    "\n",
    "print(\"Information about Testing Dataset:\")\n",
    "print(test_dataset.class_indices)\n",
    "print(test_dataset.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95hAZp2pNod6"
   },
   "source": [
    "## **7.1 Training Data Images Glimpse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "K7sTlpRSGYm7",
    "outputId": "eb65fd59-9d98-4574-a74f-d0ffc2c9f783"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols = 8, figsize = (20, 5))\n",
    "fig.suptitle(\"Samples from Training Set Batch\", fontsize = 16, fontdict = dict(weight = 'bold'))\n",
    "for curr_axis, curr_image in zip(axes.flatten(), train_dataset[0][0][:16]):\n",
    "    curr_axis.imshow(tf.squeeze(curr_image), cmap = 'gray')\n",
    "    curr_axis.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J57GRvs0NwVA"
   },
   "source": [
    "## **7.2 Validation Data Images Glimpse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "BbIpymC9V6ix",
    "outputId": "ac4a5cf6-161a-44c1-db1d-3aa3386dc8ff"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols = 8, figsize = (20, 5))\n",
    "fig.suptitle(\"Samples from Validation Set Batch\", fontsize = 16, fontdict = dict(weight = 'bold'))\n",
    "for curr_axis, curr_image in zip(axes.flatten(), validation_dataset[0][0][:16]):\n",
    "    curr_axis.imshow(tf.squeeze(curr_image), cmap = 'gray')\n",
    "    curr_axis.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8famc9WgN4lz"
   },
   "source": [
    "## **7.3 Testing Data Images Glimpse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "uPUFHOYEegwN",
    "outputId": "5a6976a7-5ffc-4745-9eaa-bd86b72f4c3c"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols = 8, figsize = (20, 5))\n",
    "fig.suptitle(\"Samples from Testing Set Batch\", fontsize = 16, fontdict = dict(weight = 'bold'))\n",
    "for curr_axis, curr_image in zip(axes.flatten(), test_dataset[0][0][:16]):\n",
    "    curr_axis.imshow(tf.squeeze(curr_image), cmap = 'gray')\n",
    "    curr_axis.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B8gfd_4gdcZ"
   },
   "source": [
    "# **8. Model Development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tG1yxOksUGsh"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwwSTwYypec1"
   },
   "outputs": [],
   "source": [
    "ROOT_CHECKPOINT_DIR_PATH = os.path.join(ROOT_DIR, \"Model-Checkpoints\")\n",
    "MLP_CHECKPOINT_DIR_PATH = os.path.join(ROOT_CHECKPOINT_DIR_PATH, \"Multi-Layer-Perceptron\")\n",
    "ALEXNET_CHECKPOINT_DIR_PATH = os.path.join(ROOT_CHECKPOINT_DIR_PATH, \"AlexNet-CNN\")\n",
    "INCEPTIONV3_CHECKPOINT_DIR_PATH = os.path.join(ROOT_CHECKPOINT_DIR_PATH, \"InceptionV3\")\n",
    "\n",
    "os.makedirs(ROOT_CHECKPOINT_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(MLP_CHECKPOINT_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(ALEXNET_CHECKPOINT_DIR_PATH, exist_ok=True)\n",
    "os.makedirs(INCEPTIONV3_CHECKPOINT_DIR_PATH, exist_ok=True)\n",
    "\n",
    "assert os.path.isdir(ROOT_CHECKPOINT_DIR_PATH) and os.path.isdir(MLP_CHECKPOINT_DIR_PATH) and os.path.isdir(ALEXNET_CHECKPOINT_DIR_PATH) and os.path.isdir(INCEPTIONV3_CHECKPOINT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xW-V8Myuq9eK"
   },
   "outputs": [],
   "source": [
    "mlp_cp_callback = ModelCheckpoint(\n",
    "    os.path.join(MLP_CHECKPOINT_DIR_PATH, \"mlp_checkpoint.weights.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "alexnet_cp_callback = ModelCheckpoint(\n",
    "    os.path.join(ALEXNET_CHECKPOINT_DIR_PATH, \"alexnet_checkpoint.weights.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "inceptionv3_cp_callback = ModelCheckpoint(\n",
    "    os.path.join(INCEPTIONV3_CHECKPOINT_DIR_PATH, \"inceptionv3_checkpoint.weights.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tv8oR0WTjf32"
   },
   "outputs": [],
   "source": [
    "def training_process_viz(training_stats: pd.DataFrame, **plot_kwargs) -> None:\n",
    "    fig, axes = plt.subplots(ncols = 2, figsize = (15, 5))\n",
    "    fig.suptitle(plot_kwargs['plot_title'], fontsize = 16, fontdict = dict(weight = 'bold'), y = 1.08)\n",
    "    for curr_axis, col_name in zip(axes, ['accuracy', 'loss']):\n",
    "        curr_axis.grid(True, alpha = 0.3)\n",
    "        curr_axis.set_title(f\"Model {col_name}\".title(), fontsize = 14)\n",
    "        sns.lineplot(x = range(1, 1 + training_stats.shape[0]), y = training_stats[col_name], color = 'blue', ax = curr_axis)\n",
    "        sns.lineplot(x = range(1, 1 + training_stats.shape[0]), y = training_stats[f\"val_{col_name}\"], color = 'red', ax = curr_axis)\n",
    "        curr_axis.set_xlabel(\"Epochs\", fontsize = 12)\n",
    "        curr_axis.set_ylabel(col_name.title(), fontsize = 12)\n",
    "        curr_axis.tick_params(which = 'major', labelsize = 12)\n",
    "        curr_axis.legend([col_name.title(), f\"validation {col_name}\".title()], title = col_name.title())\n",
    "    fig.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvwEwnWn7K62"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_viz(model, test_dataset, **plot_kwargs) -> None:\n",
    "    assert isinstance(model, Sequential)\n",
    "    model_preds = [np.argmax(curr_row) for curr_row in model.predict(test_dataset)]\n",
    "    fig, axis = plt.subplots(figsize = (8, 6))\n",
    "    class_names = ['Glioma', 'Meningioma', 'No-Tumor', 'Pituitary\\nTumor']\n",
    "    sns.heatmap(confusion_matrix(test_dataset.classes, model_preds), annot = True, cmap = plt.cm.Reds, ax = axis)\n",
    "    axis.set_title(plot_kwargs['plot_title'], fontsize = 14)\n",
    "    axis.tick_params(which = 'major', labelsize = 12)\n",
    "    axis.set_xlabel(\"Pedicted Class\", fontsize = 12)\n",
    "    axis.set_ylabel(\"Actual Class\", fontsize = 12)\n",
    "    axis.set_xticklabels(class_names, fontdict = dict(fontsize = 12))\n",
    "    axis.set_yticklabels(class_names, fontdict = dict(fontsize = 12))\n",
    "    fig.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4dcEUM6Hdz3"
   },
   "outputs": [],
   "source": [
    "def generate_report(*models, test_dataset, row_indexes) -> pd.DataFrame:\n",
    "    assert len(models)\n",
    "    report_df = pd.DataFrame(columns = ['MAE', 'MSE', 'RMSE', 'Loss', 'Accuracy', 'F1-Score'])\n",
    "    y_hat = test_dataset.classes # y_hat = ground_truth\n",
    "    for curr_index, curr_model in enumerate(models):\n",
    "        assert isinstance(curr_model, Sequential)\n",
    "        curr_model_loss, curr_model_accuracy = curr_model.evaluate(test_dataset)\n",
    "        y_preds = [np.argmax(curr_preds) for curr_preds in curr_model.predict(test_dataset)]\n",
    "        report_df.loc[curr_index] = [mean_absolute_error(y_hat, y_preds), mean_squared_error(y_hat, y_preds), mean_squared_error(y_hat, y_preds, squared = False), curr_model_loss, curr_model_accuracy, f1_score(y_hat, y_preds, average = \"micro\")]\n",
    "    report_df.index = row_indexes\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0amnN1WhVC6"
   },
   "source": [
    "## **8.1 EfficientNet B0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuqCK37HOOzN"
   },
   "source": [
    "### **8.1.1 Development of Multi-Layer Perceptron Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "RhmSS-3Qe2TA",
    "outputId": "cb7916f0-38cb-4358-891d-e16852029830"
   },
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "mlp_model.add(Flatten(input_shape = (image_size, image_size, 3), name = 'Flatten-Layer'))\n",
    "mlp_model.add(Dense(2048, activation = 'relu', name = 'Hidden-Layer-1'))\n",
    "mlp_model.add(Dropout(rate = 0.2, name = 'Dropout-Layer-1'))\n",
    "mlp_model.add(Dense(1024, activation = 'relu', name = 'Hidden-Layer-2'))\n",
    "mlp_model.add(Dropout(rate = 0.2, name = 'Dropout-Layer-2'))\n",
    "mlp_model.add(Dense(512, activation = 'relu', name = 'Hidden-Layer-3'))\n",
    "mlp_model.add(Dropout(rate = 0.2, name = 'Dropout-Layer-3'))\n",
    "mlp_model.add(Dense(4, activation = 'softmax', name = 'Output-Layer-1'))\n",
    "mlp_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szJHcRmDODTD"
   },
   "source": [
    "### **8.1.2 Training and Validation of Multi-Layer Perceptron Based Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cnt8HTzsh-rs",
    "outputId": "3b30210d-d39b-4f73-dabb-753a981435c8"
   },
   "outputs": [],
   "source": [
    "with tf.device(gpu_device_location) if gpu_device_location else tpu_strategy.scope() if tpu_device_location else tf.device(cpu_device_location):\n",
    "    mlp_train_history = mlp_model.fit(train_dataset,\n",
    "                                      batch_size = batch_size,\n",
    "                                      validation_data = validation_dataset,\n",
    "                                      epochs = 100,\n",
    "                                      callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_sWTx4-OWGo"
   },
   "source": [
    "### **8.1.3 Multi-Layer Perceptron Based Model Training Process Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "9qUbIlzKwo-V",
    "outputId": "b3203af3-eb03-439e-f5b8-fecb962a2228"
   },
   "outputs": [],
   "source": [
    "training_process_viz(pd.DataFrame(mlp_train_history.history),\n",
    "                     plot_title = 'Multilayer Perceptron Training Statistics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLIHKr3YOexp"
   },
   "source": [
    "### **8.1.4 Confusion Matrix for Multi-Layer Perceptron Based Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6JY5n8GT82jA",
    "outputId": "83cc9bc0-4a70-41ec-9fad-b10a64d51ccd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix_viz(mlp_model, train_dataset, plot_title = \"MLP Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-Vg-CJnFCAa",
    "outputId": "1bb7cf80-e404-49fc-dcfe-38ad692c0369",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_report_df = generate_report(mlp_model,\n",
    "                                test_dataset = test_dataset,\n",
    "                                row_indexes = (\"Multi-Layer-Perceptron Model\",))\n",
    "mlp_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nobbz__oKJgb"
   },
   "source": [
    "## **9. Conclusions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "name": "Brain-Tumor-MRI-Image-Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
